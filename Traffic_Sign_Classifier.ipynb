{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.9.0-rc0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The German Traffic Sign Recognition Benchmark [*](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset)\n",
    "\n",
    "The below code assumes dataset files are placed in ./data folder and in specific subfolders of ./data\n",
    "\n",
    "A convenience dataset download script `download_dataset.ssh` is included in this project directory, use this script to download the German Traffic Sign dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 0: Load The Data\n",
    "\n",
    "`dataset` is a dictionary of dictionary with the following structure\n",
    "<code style=\"background-color: #fff; font-size: 11px; line-height: 3px;\">\n",
    "    dataset = {\n",
    "        'train' : {\n",
    "            'X' : python-list of Image FileName Strings\n",
    "            'y' : python-list of corresponding class name numbers\n",
    "        }\n",
    "        'val' : {\n",
    "            'X' : python-list of Image FileName Strings\n",
    "            'y' : python-list of corresponding class name numbers\n",
    "        }\n",
    "        'test' : {\n",
    "            'X' : python-list of Image FileName Strings\n",
    "            'y' : python-list of corresponding class name numbers\n",
    "        }\n",
    "    }\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "_BATCH_SIZE = 32\n",
    "_NUM_CLASS = 43\n",
    "_IMG_SHAPE = (32, 32, 3)\n",
    "\n",
    "init_global_vars(_NUM_CLASS, _IMG_SHAPE, _BATCH_SIZE)\n",
    "\n",
    "dataset = get_traffic_sign_dataset();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training   examples = 35288\n",
      "Number of validation examples = 3921\n",
      "Number of testing    examples = 12630\n",
      "\n",
      "\n",
      "Image data shape  = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training   examples =\", len(dataset[\"train\"][\"X\"]))\n",
    "print(\"Number of validation examples =\", len(dataset[\"val\"][\"X\"]))\n",
    "print(\"Number of testing    examples =\", len(dataset[\"test\"][\"X\"]))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Image data shape  =\", _IMG_SHAPE)\n",
    "print(\"Number of classes =\", _NUM_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000, Speed limit (20km/h)\n",
      "001, Speed limit (30km/h)\n",
      "002, Speed limit (50km/h)\n",
      "003, Speed limit (60km/h)\n",
      "004, Speed limit (70km/h)\n",
      "005, Speed limit (80km/h)\n",
      "006, End of speed limit (80km/h)\n",
      "007, Speed limit (100km/h)\n",
      "008, Speed limit (120km/h)\n",
      "009, No passing\n",
      "010, No passing for vehicles over 3.5 metric tons\n",
      "011, Right-of-way at the next intersection\n",
      "012, Priority road\n",
      "013, Yield\n",
      "014, Stop\n",
      "015, No vehicles\n",
      "016, Vehicles over 3.5 metric tons prohibited\n",
      "017, No entry\n",
      "018, General caution\n",
      "019, Dangerous curve to the left\n",
      "020, Dangerous curve to the right\n",
      "021, Double curve\n",
      "022, Bumpy road\n",
      "023, Slippery road\n",
      "024, Road narrows on the right\n",
      "025, Road work\n",
      "026, Traffic signals\n",
      "027, Pedestrians\n",
      "028, Children crossing\n",
      "029, Bicycles crossing\n",
      "030, Beware of ice/snow\n",
      "031, Wild animals crossing\n",
      "032, End of all speed and passing limits\n",
      "033, Turn right ahead\n",
      "034, Turn left ahead\n",
      "035, Ahead only\n",
      "036, Go straight or right\n",
      "037, Go straight or left\n",
      "038, Keep right\n",
      "039, Keep left\n",
      "040, Roundabout mandatory\n",
      "041, End of no passing\n",
      "042, End of no passing by vehicles over 3.5 metric tons\n"
     ]
    }
   ],
   "source": [
    "class_name_dict = get_class_name_dict()\n",
    "\n",
    "for k, v in class_name_dict.items():\n",
    "    print(\"{:03d}, {:s}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(dataset[\"train\"][\"y\"], 'Frequency of Class Examples in training dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(dataset[\"val\"][\"y\"], 'Frequency of Class Examples in validation dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Generating Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set\n",
    "\n",
    "### [Normalization](https://en.wikipedia.org/wiki/Normalization_%28image_processing%29)\n",
    "\n",
    "Normalization transforms an n-dimensional grayscale image $I:\\{{\\mathbb  {X}}\\subseteq {\\mathbb  {R}}^{n}\\}\\rightarrow \\{{\\text{Min}},..,{\\text{Max}}\\}$ with intensity values in the range (Min, Max), into a new image $I_{N}:\\{{\\mathbb  {X}}\\subseteq {\\mathbb  {R}}^{n}\\}\\rightarrow \\{{\\text{newMin}},..,{\\text{newMax}}\\}$ with intensity values in the range (newMin, newMax).\n",
    "\n",
    "The linear normalization of a grayscale digital image is performed according to the formula.\n",
    "\n",
    "$I_{N}=(I-{\\text{Min}}){\\frac  {{\\text{newMax}}-{\\text{newMin}}}{{\\text{Max}}-{\\text{Min}}}}+{\\text{newMin}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_dataset`, `val_dataset` and `test_dataset` (created in a later cell) are tf.data objects\n",
    "\n",
    "`repeat()` is used so that tf.data iterator does not run out of training examples or so that iterator behaves like a circular list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = covert_to_tf_dataset(dataset[\"train\"])\n",
    "val_dataset = covert_to_tf_dataset(dataset[\"val\"])\n",
    "\n",
    "# next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: LeNet-5 Neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "\n",
    "μ = 0.0\n",
    "σ = 0.05\n",
    "\n",
    "'''\n",
    ":::: Defaults ::::\n",
    "      Conv2D: padding='valid', strides=(1, 1), use_bias=True, \n",
    "              bias_initializer='zeros'\n",
    "              \n",
    "MaxPooling2D: pool_size=(2, 2), strides=None, padding='valid'\n",
    "\n",
    "       Dense: use_bias=True, bias_initializer='zeros'\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input doesn't return a layer\n",
    "# if you are using Sequential, you may also skip the Input\n",
    "# and just specify the input_shape for the first Layer.\n",
    "# model.add(Input(shape=(32, 32, 3)))\n",
    "\n",
    "# In: (?, 32, 32, 3) | Out: (?, 28, 28, 6)\n",
    "model.add(Conv2D(6, (5, 5), activation='relu',\n",
    "                 kernel_initializer=TruncatedNormal(mean=μ, stddev=σ),\n",
    "                 name='conv1'))\n",
    "# In: (?, 28, 28, 6) | Out: (?, 14, 14, 6)\n",
    "model.add(MaxPooling2D(strides=(2, 2), name='conv1_max_p'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# In: (?, 14, 14, 6) | Out: (?, 10, 10, 16)\n",
    "model.add(Conv2D(16, (5, 5), activation='relu',\n",
    "                 kernel_initializer=TruncatedNormal(mean=μ, stddev=σ),\n",
    "                 name='conv2'))\n",
    "# In: (?, 10, 10, 16) | Out: (?, 5, 5, 16)\n",
    "model.add(MaxPooling2D(strides=(2, 2), name='conv2_max_p'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# In: (?, 5, 5, 16) | Out: (?, 400) {400 = 5*5*16}\n",
    "model.add(Flatten(name='flatten'))\n",
    "\n",
    "# In: (?, 400) | Out: (?, 120)\n",
    "model.add(Dense(120, activation='relu',\n",
    "                kernel_initializer=TruncatedNormal(mean=μ, stddev=σ),\n",
    "                name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# In: (?, 120) | Out: (?, 84)\n",
    "model.add(Dense(84, activation='relu',\n",
    "                kernel_initializer=TruncatedNormal(mean=μ, stddev=σ),\n",
    "                name='fc2'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# In: (?, 84) | Out: (?, num_classes)\n",
    "model.add(Dense(_NUM_CLASS, activation='softmax',\n",
    "                kernel_initializer=TruncatedNormal(mean=μ, stddev=σ), \n",
    "                name='fc3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- categorical_crossentropy should be used when labels are one_hot_encoded\n",
    "- sparse_categorical_crossentropy for numbered labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(3e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing.\n",
    "A low accuracy on the training and validation sets imply underfitting.\n",
    "A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.fit() and model.evaluate()\n",
    "\n",
    "when using tf.data as input make sure to include steps parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "_EPOCHS = 50\n",
    "_LOAD_MODEL = True\n",
    "\n",
    "_MODEL_FILE = \"./model/checkpoints/model_chkpt\"\n",
    "_HISTORY_FILE = \"./model/train_history/train_history_dict.p\"\n",
    "\n",
    "history = None\n",
    "\n",
    "if not _LOAD_MODEL:\n",
    "    historyObj = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = len(dataset[\"train\"][\"X\"]) // _BATCH_SIZE,\n",
    "        epochs = _EPOCHS,\n",
    "        validation_data = val_dataset,\n",
    "        validation_steps = len(dataset[\"val\"][\"X\"]) // _BATCH_SIZE,\n",
    "        verbose = 1\n",
    "    )\n",
    "    history = historyObj.history\n",
    "    \n",
    "    os.system(\"spd-say 'Model Trained'\")\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.save_weights(_MODEL_FILE)\n",
    "    print(\"Saved model weights to disk\")\n",
    "    \n",
    "    with open(_HISTORY_FILE, 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "    print(\"Training history saved\")\n",
    "    \n",
    "else:\n",
    "    model.load_weights(_MODEL_FILE)\n",
    "    print(\"Model weights loaded from disk\")\n",
    "\n",
    "    with open(_HISTORY_FILE, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "    print(\"Training history loaded from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line_graphs(_EPOCHS, history['val_acc'], y1_label = \"Validation Accuracy\",\n",
    "                y2 = history['acc'], y2_label = \"Training Accuracy\",\n",
    "                title = \"Validation Accuracy vs Training Accuracy\",\n",
    "                xlabel = \"Epoch(s)\", ylabel = \"Accuracy\",\n",
    "                legend_loc = \"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line_graphs(_EPOCHS, history['val_loss'], y1_label = \"Validation Loss\",\n",
    "                y2 = history['loss'], y2_label = \"Training Loss\",\n",
    "                title = \"Validation Loss vs Training Loss\",\n",
    "                xlabel = \"Epoch(s)\", ylabel = \"Loss\",\n",
    "                legend_loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Testing the Model\n",
    "\n",
    "[`evaluate()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset =  covert_to_tf_dataset(dataset[\"test\"], repeat = False)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_dataset, \n",
    "                                    steps = len(dataset[\"test\"][\"X\"]) // _BATCH_SIZE,\n",
    "                                    verbose=1,)\n",
    "\n",
    "print('\\n')\n",
    "print('Test set loss:', test_loss)\n",
    "print('Test set accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more insight into how our model is working, we downloaded few pictures of German traffic signs from the web and used our model to predict the traffic sign type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_db = get_examples_dataset()\n",
    "example_tf_db = covert_to_tf_dataset(example_db, repeat = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(example_tf_db, steps = _BATCH_SIZE)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyzing  Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top K Predictions\n",
    "[`tf.nn.top_k`](https://www.tensorflow.org/api_docs/python/tf/nn/top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "probabilities, y_pred = tf.nn.top_k(predictions, k = top_k, sorted = True)\n",
    "probabilities = probabilities.numpy()\n",
    "y_pred = y_pred.numpy()\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Css Styles</p>\n",
    "\n",
    "<style></style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will generate an HTML table to easily compared the predictions of our model. The last column of the plot shows the bar chart of class confidence, to see full size plot.\n",
    "\n",
    "- Right click on the bar chart\n",
    "- Copy Image Location\n",
    "- Open this Image location in a new browser tab/window\n",
    "\n",
    "OR (If this option is available) Directly open image in new tab/window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "N, K = probabilities.shape\n",
    "correct_pred_count = 0\n",
    "\n",
    "htmlMarkup = \"<table>\"\n",
    "htmlMarkup += \"<tr>\"\n",
    "htmlMarkup += \"<th>Class#</th>\"\n",
    "htmlMarkup += \"<th>Image</th>\"\n",
    "htmlMarkup += \"<th>Label</th>\"\n",
    "htmlMarkup += \"<th>Model Top {:d} Predictions</th>\".format(top_k)\n",
    "htmlMarkup += \"<th>All Predictions</th>\"\n",
    "htmlMarkup += \"</tr>\"\n",
    "\n",
    "for n in np.arange(N):\n",
    "    correct_pred = False\n",
    "    if y_pred[n][0] == example_db[\"y\"][n]:\n",
    "        correct_pred = True\n",
    "        correct_pred_count = (correct_pred_count + 1)\n",
    "\n",
    "    style = \"style='color: red;'\" if not correct_pred else \"\"\n",
    "    htmlMarkup += \"<tr {}>\".format(style)\n",
    "    htmlMarkup += \"<td>{}</td>\".format(example_db[\"y\"][n])\n",
    "    htmlMarkup += \"<td><img src='{}' height='128' width='128'/></td>\"\\\n",
    "                    .format(example_db[\"X\"][n])\n",
    "    htmlMarkup += \"<td>{}</td>\".format(class_name_dict[example_db[\"y\"][n]])\n",
    "\n",
    "    s = \"\"\n",
    "    for k in np.arange(K):\n",
    "        s += \"<p>{:5.4f}, {} ({})</p>\"\\\n",
    "                .format(probabilities[n][k],\n",
    "                        class_name_dict[y_pred[n][k]],\n",
    "                        y_pred[n][k])\n",
    "    htmlMarkup += \"<td>{}</td>\".format(s)\n",
    "\n",
    "    x = example_db[\"X\"][n].rfind(\"/\")\n",
    "    y = example_db[\"X\"][n].rfind(\".\")\n",
    "    fileName = \"./plots/example-predictions/\" +\\\n",
    "                example_db[\"X\"][n][x + 1 : y] + \".png\"\n",
    "\n",
    "    plot_bar_chart(predictions[n], \"\", \"class num\", \"confidence\", fileName)\n",
    "\n",
    "    htmlMarkup += \"<td><img src='{}' height='128' width='256'/></td>\"\\\n",
    "                    .format(fileName)\n",
    "    htmlMarkup += \"</tr>\"\n",
    "\n",
    "htmlMarkup += \"</table>\"\n",
    "\n",
    "display(HTML(htmlMarkup))\n",
    "\n",
    "print(\"{}/{} correctly classfified with an accuracy of {:5.4f}\"\\\n",
    "    .format(correct_pred_count,\n",
    "           N,\n",
    "           correct_pred_count/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix, Accuracy, Precison and Recall\n",
    "\n",
    "[`tf.nn.top_k`](https://www.tensorflow.org/api_docs/python/tf/nn/top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "_, y_pred = tf.nn.top_k(predictions, k = 1, sorted = True)\n",
    "y_test = np.array(example_db[\"y\"])\n",
    "\n",
    "y_pred = y_pred.numpy().reshape(-1)\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, \n",
    "                              labels = list(class_name_dict.keys()))\n",
    "\n",
    "print(\"cnf_matrix.shape: \", cnf_matrix.shape)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes = list(class_name_dict.values()),\n",
    "                      title='Confusion matrix, without normalization')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Visualize the Neural Network's State with Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\"\"\"\n",
    "activation should be of shape (1, H, W, C)\n",
    "plt_num: used to plot out multiple different weight feature map sets on the same block,\n",
    "        just extend the plt number for each new feature map entry\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def visualize_conv_layer_out(activation, activation_min = -1, activation_max = -1, plt_num = 1):\n",
    "    _, H, W, C = activation.shape\n",
    "    num_cols = math.floor(84 / H)\n",
    "    num_rows = math.ceil(H / num_cols)\n",
    "    plt.figure(plt_num, figsize=(num_rows, num_cols))\n",
    "\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(figsize = (20, int(num_rows * H / 4.5))) # (width, height)\n",
    "    \n",
    "    for c in np.arange(C):\n",
    "        # sets the number of feature maps to show on each row and column\n",
    "        plt.subplot(num_rows, num_cols, c + 1)\n",
    "        plt.axis('off')\n",
    "        # displays the feature map number\n",
    "        plt.title('Feature Map ' + str(c))\n",
    "        \n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, c],\n",
    "                       interpolation=\"nearest\",\n",
    "                       vmin = activation_min,\n",
    "                       vmax = activation_max,\n",
    "                       cmap = \"gray\")\n",
    "        \n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, c],\n",
    "                       interpolation=\"nearest\",\n",
    "                       vmax = activation_max,\n",
    "                       cmap=\"gray\")\n",
    "        \n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, c],\n",
    "                       interpolation = \"nearest\",\n",
    "                       vmin = activation_min,\n",
    "                       cmap = \"gray\")\n",
    "        \n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, c],\n",
    "                       interpolation=\"nearest\",\n",
    "                       cmap = \"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "\n",
    "def get_intermediate_layer_output(layer_name, x_test):\n",
    "    layer = model.get_layer(name = layer_name)\n",
    "    intermediate_layer_model = keras.Model(inputs = model.input, outputs = layer.output)\n",
    "    return intermediate_layer_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Convolution activations of layer `conv1` and layer `conv2`  for  ` N`  random test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "N = 3\n",
    "L = len(dataset[\"test\"][\"y\"])\n",
    "\n",
    "for _ in np.arange(N):\n",
    "    num = np.random.randint(L)\n",
    "    viz_db = {\n",
    "        \"X\" : [],\n",
    "        \"y\" : []\n",
    "    }\n",
    "    viz_db[\"X\"].append(dataset[\"test\"][\"X\"][num])\n",
    "    viz_db[\"y\"].append(dataset[\"test\"][\"y\"][num])\n",
    "    \n",
    "    plt.figure(figsize = (3, 3))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(io.imread(viz_db[\"X\"][0]))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    x_test, y_test = next(iter(covert_to_tf_dataset(viz_db, repeat = False)))\n",
    "    \n",
    "    print(\"conv1 visualization\")\n",
    "    visualize_conv_layer_out(get_intermediate_layer_output(\"conv1\", x_test))\n",
    "    \n",
    "    print(\"conv2 visualization\")\n",
    "    visualize_conv_layer_out(get_intermediate_layer_output(\"conv2\", x_test))\n",
    "    \n",
    "    display(HTML(\"<hr style='border: 0;\"\n",
    "                 + \" width: 100%;\" \n",
    "                 + \" color: #f00;\"\n",
    "                 + \" background-color: red;\"\n",
    "                 + \" height: 7px;'/>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
