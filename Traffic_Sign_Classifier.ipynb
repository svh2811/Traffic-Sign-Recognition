{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition Classifier\n",
    "\n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission. \n",
    "\n",
    "In addition to implementing code, there is a writeup to complete. The writeup should be completed in a separate file, which can be either a markdown file or a pdf document. There is a [write up template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) that can be used to guide the writing process. Completing the code template and writeup template will cover all of the [rubric points](https://review.udacity.com/#!/rubrics/481/view) for this project.\n",
    "\n",
    "The [rubric](https://review.udacity.com/#!/rubrics/481/view) contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this Ipython notebook and also discuss the results in the writeup file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The German Traffic Sign Recognition Benchmark [*](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset)\n",
    "\n",
    "The below code assumes dataset files are placed in ./data folder and in specific subfolders of ./data\n",
    "\n",
    "A convenience dataset download script `download_dataset.ssh` is included in this project directory, use this script to download the German Traffic Sign dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 0: Load The Data\n",
    "\n",
    "`dataset` is a dictionary of dictionary with the following structure\n",
    "<code style=\"background-color: #fff; font-size: 11px; line-height: 3px;\">\n",
    "    dataset = {\n",
    "        'train' : {\n",
    "            'X' : python-list of Image FileName Strings\n",
    "            'y' : python-list of corresponding class name numbers\n",
    "        }\n",
    "        'val' : {\n",
    "            'X' : python-list of Image FileName Strings\n",
    "            'y' : python-list of corresponding class name numbers\n",
    "        }\n",
    "        'test' : {\n",
    "            'X' : python-list of Image FileName Strings\n",
    "            'y' : python-list of corresponding class name numbers\n",
    "        }\n",
    "    }\n",
    "</code>\n",
    "\n",
    "`train_dataset`, `val_dataset` and `test_dataset` are tf.data objects\n",
    "\n",
    "`repeat()` is used so that tf.data iterator does not run out of training examples or so that iterator behaves like a circular list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)\n",
    "\n",
    "Minimally, the image data should be normalized so that the data has mean zero and equal variance. For image data, `(pixel - 128)/ 128` is a quick way to approximately normalize the data and can be used in this project. \n",
    "\n",
    "Other pre-processing steps are optional. You can try different techniques to see if it improves performance. \n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "_BATCH_SIZE = 32\n",
    "_NUM_CLASS = 43\n",
    "_IMG_SHAPE = (32, 32, 3)\n",
    "\n",
    "init_global_vars(_NUM_CLASS, _IMG_SHAPE, _BATCH_SIZE)\n",
    "\n",
    "dataset = get_traffic_sign_dataset();\n",
    "\n",
    "train_dataset = covert_to_tf_dataset(dataset[\"train\"])\n",
    "val_dataset = covert_to_tf_dataset(dataset[\"val\"])\n",
    "test_dataset =  covert_to_tf_dataset(dataset[\"test\"])\n",
    "\n",
    "# next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training   examples =\", len(dataset[\"train\"][\"X\"]))\n",
    "print(\"Number of validation examples =\", len(dataset[\"val\"][\"X\"]))\n",
    "print(\"Number of testing    examples =\", len(dataset[\"test\"][\"X\"]))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Image data shape  =\", _IMG_SHAPE)\n",
    "print(\"Number of classes =\", _NUM_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_dict = get_class_name_dict()\n",
    "\n",
    "for k, v in class_name_dict.items():\n",
    "    print(\"{:03d}, {:s}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the dataset\n",
    "\n",
    "**NOTE:** It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections. It can be interesting to look at the distribution of classes in the training, validation and test set. Is the distribution the same? Are there more examples of some classes than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.path as path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matplotlib.org/gallery/api/histogram_path.html#sphx-glr-gallery-api-histogram-path-py\n",
    "\n",
    "def plot_histogram(labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    n, bins = np.histogram(labels, _NUM_CLASS)\n",
    "    \n",
    "    # get the corners of the rectangles for the histogram\n",
    "    left = np.array(bins[:-1])\n",
    "    right = np.array(bins[1:])\n",
    "    bottom = np.zeros(len(left))\n",
    "    top = bottom + n\n",
    "    \n",
    "    # we need a (numrects x numsides x 2) numpy array for the path helper\n",
    "    # function to build a compound path\n",
    "    XY = np.array([[left, left, right, right], [bottom, top, top, bottom]]).T\n",
    "\n",
    "    # get the Path object\n",
    "    barpath = path.Path.make_compound_path_from_polys(XY)\n",
    "\n",
    "    # make a patch out of it\n",
    "    patch = patches.PathPatch(barpath)\n",
    "    ax.add_patch(patch)\n",
    "\n",
    "    # update the view limits\n",
    "    ax.set_xlim(left[0], right[-1])\n",
    "    ax.set_ylim(bottom.min(), top.max())\n",
    "    \n",
    "    plt.xlabel('Class Number')\n",
    "    plt.ylabel('Class Count')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(dataset[\"train\"][\"y\"], 'Frequency of Class Examples in training dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(dataset[\"val\"][\"y\"], 'Frequency of Class Examples in validation dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: LeNet-5 Neural network architecture\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). \n",
    "\n",
    "It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "\n",
    "μ = 0.0\n",
    "σ = 0.05\n",
    "\n",
    "'''\n",
    ":::: Defaults ::::\n",
    "      Conv2D: padding='valid', strides=(1, 1), use_bias=True, bias_initializer='zeros'\n",
    "MaxPooling2D: pool_size=(2, 2), strides=None, padding='valid'\n",
    "       Dense: use_bias=True, bias_initializer='zeros'\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input doesn't return a layer\n",
    "# if you are using Sequential, you may also skip the Input\n",
    "# and just specify the input_shape for the first Layer.\n",
    "# model.add(Input(shape=(32, 32, 3)))\n",
    "\n",
    "# In: (?, 32, 32, 3) | Out: (?, 28, 28, 6)\n",
    "model.add(Conv2D(6, (5, 5), activation='relu', kernel_initializer=TruncatedNormal(mean=μ, stddev=σ), name='conv1'))\n",
    "# In: (?, 28, 28, 6) | Out: (?, 14, 14, 6)\n",
    "model.add(MaxPooling2D(strides=(2, 2), name='conv1_max_p'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# In: (?, 14, 14, 6) | Out: (?, 10, 10, 16)\n",
    "model.add(Conv2D(16, (5, 5), activation='relu', kernel_initializer=TruncatedNormal(mean=μ, stddev=σ), name='conv2'))\n",
    "# In: (?, 10, 10, 16) | Out: (?, 5, 5, 16)\n",
    "model.add(MaxPooling2D(strides=(2, 2), name='conv2_max_p'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# In: (?, 5, 5, 16) | Out: (?, 400) {400 = 5*5*16}\n",
    "model.add(Flatten(name='flatten'))\n",
    "\n",
    "# In: (?, 400) | Out: (?, 120)\n",
    "model.add(Dense(120, activation='relu', kernel_initializer=TruncatedNormal(mean=μ, stddev=σ), name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# In: (?, 120) | Out: (?, 84)\n",
    "model.add(Dense(84, activation='relu', kernel_initializer=TruncatedNormal(mean=μ, stddev=σ), name='fc2'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# In: (?, 84) | Out: (?, num_classes)\n",
    "model.add(Dense(_NUM_CLASS, activation='softmax', kernel_initializer=TruncatedNormal(mean=μ, stddev=σ), name='fc3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- categorical_crossentropy should be used when labels are one_hot_encoded\n",
    "- sparse_categorical_crossentropy for numbered labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(3e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing.\n",
    "A low accuracy on the training and validation sets imply underfitting.\n",
    "A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.fit() and model.evaluate()\n",
    "\n",
    "when using tf.data as input make sure to include steps parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "_EPOCHS = 50\n",
    "_LOAD_MODEL = True\n",
    "\n",
    "_MODEL_FILE = \"./model/checkpoints/model_chkpt\"\n",
    "_HISTORY_FILE = \"./model/train_history/train_history_dict.p\"\n",
    "\n",
    "history = None\n",
    "\n",
    "if not _LOAD_MODEL:\n",
    "    historyObj = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = len(dataset[\"train\"][\"X\"]) // _BATCH_SIZE,\n",
    "        epochs = _EPOCHS,\n",
    "        validation_data = val_dataset,\n",
    "        validation_steps = len(dataset[\"val\"][\"X\"]) // _BATCH_SIZE,\n",
    "        verbose = 1\n",
    "    )\n",
    "    history = historyObj.history\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    os.system(\"spd-say 'Model Trained'\")\n",
    "    \n",
    "    model.save_weights(_MODEL_FILE)\n",
    "    print(\"Saved model weights to disk\")\n",
    "    \n",
    "    with open(_HISTORY_FILE, 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "    print(\"Training history saved\")\n",
    "    \n",
    "else:\n",
    "    model.load_weights(_MODEL_FILE)\n",
    "    print(\"Model weights loaded from disk\")\n",
    "\n",
    "    with open(_HISTORY_FILE, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "    print(\"Training history loaded from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(_EPOCHS)\n",
    "\n",
    "plt.plot(epochs, history['val_acc'], 'b.-', label = \"Validation Accuracy\")\n",
    "plt.plot(epochs, history['acc'], 'r.-', label = \"Training Accuracy\")\n",
    "plt.title('Validation Accuracy vs Training Accuracy')\n",
    "plt.xlabel('Epoch(s)')\n",
    "plt.ylabel('Accuracy')\n",
    "leg = plt.legend(loc = 'lower right')\n",
    "leg.get_frame().set_alpha(0.5)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, history['val_loss'], 'b.-', label = \"Validation Loss\")\n",
    "plt.plot(epochs, history['loss'], 'r.-', label = \"Training Loss\")\n",
    "plt.title('Validation Loss vs Training Loss')\n",
    "plt.xlabel('Epoch(s)')\n",
    "plt.ylabel('Loss')\n",
    "leg = plt.legend(loc = 'upper right')\n",
    "leg.get_frame().set_alpha(0.5)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To plot Model Arch, the following packages need to be installed, pydot, pydot-ng & graphviz\n",
    "\n",
    "`pip3 install pydot --user`\n",
    "\n",
    "`pip3 install graphviz --user`\n",
    "\n",
    "`pip3 install pydot-ng --user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(model, show_shapes=True, to_file='./model/model_arch.png')\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from tensorflow.keras.utils.vis_utils import model_to_dot\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset, steps = len(dataset[\"test\"][\"X\"]) // _BATCH_SIZE)\n",
    "\n",
    "print('\\n')\n",
    "print('Test set loss:', test_loss)\n",
    "print('Test set accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more insight into how our model is working, we downloaded few pictures of German traffic signs from the web and used our model to predict the traffic sign type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_db = get_examples_dataset()\n",
    "example_tf_db = covert_to_tf_dataset(example_db, repeat = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(example_tf_db, steps = _BATCH_SIZE)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance\n",
    "\n",
    "[`tf.nn.top_k`](https://www.tensorflow.org/api_docs/python/tf/nn/top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = tf.nn.top_k(predictions, k = 5, sorted = True)\n",
    "values = values.numpy()\n",
    "indices = indices.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N, K = values.shape\n",
    "correct_pred = 0\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "htmlMarkup = \"<table>\"\n",
    "htmlMarkup += \"<tr>\"\n",
    "htmlMarkup += \"<th>Class#</th>\"\n",
    "htmlMarkup += \"<th>Image</th>\"\n",
    "htmlMarkup += \"<th>Label</th>\"\n",
    "htmlMarkup += \"<th>Model Prediction</th>\"\n",
    "htmlMarkup += \"</tr>\"\n",
    "\n",
    "for n in np.arange(N):\n",
    "    correct_pred = (correct_pred + 1) if indices[n][0] == example_db[\"y\"][n] else correct_pred\n",
    "    htmlMarkup += \"<tr>\"\n",
    "    htmlMarkup += \"<td>{}</td>\".format(example_db[\"y\"][n])\n",
    "    htmlMarkup += \"<td><img src='{}' height='128' width='128'/></td>\".format(example_db[\"X\"][n])\n",
    "    htmlMarkup += \"<td>{}</td>\".format(class_name_dict[example_db[\"y\"][n]])\n",
    "    s = \"\"\n",
    "    for k in np.arange(K):\n",
    "        s += \"<p>{:5.4f}, {}, ({})</p>\".format(values[n][k], class_name_dict[indices[n][k]], indices[n][k])\n",
    "    htmlMarkup += \"<td>{}</td>\".format(s)\n",
    "    htmlMarkup += \"</tr>\"\n",
    "\n",
    "htmlMarkup += \"</table>\"\n",
    "display(HTML(htmlMarkup))\n",
    "\n",
    "print(\"{}/{} correctly classfified with an accuracy of {:5.4f}\".format(correct_pred, N, correct_pred/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Visualize the Neural Network's State with Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\"\"\"\n",
    "activation should be of shape (1, H, W, C)\n",
    "plt_num: used to plot out multiple different weight feature map sets on the same block,\n",
    "        just extend the plt number for each new feature map entry\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def visualize_conv_layer_out(activation, activation_min = -1, activation_max = -1, plt_num = 1):\n",
    "    _, H, W, C = activation.shape\n",
    "    num_cols = math.floor(84 / H)\n",
    "    num_rows = math.ceil(H / num_cols)\n",
    "    plt.figure(plt_num, figsize=(num_rows, num_cols))\n",
    "\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(figsize = (20, int(num_rows * H / 4.5))) # (width, height)\n",
    "    \n",
    "    for c in np.arange(C):\n",
    "        # sets the number of feature maps to show on each row and column\n",
    "        plt.subplot(num_rows, num_cols, c + 1)\n",
    "        plt.axis('off')\n",
    "        # displays the feature map number\n",
    "        plt.title('Feature Map ' + str(c))\n",
    "        \n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, c], interpolation=\"nearest\", vmin = activation_min,\n",
    "                       vmax = activation_max, cmap = \"gray\")\n",
    "        \n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, c], interpolation=\"nearest\", vmax = activation_max, cmap=\"gray\")\n",
    "        \n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, c], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        \n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, c], interpolation=\"nearest\", cmap=\"gray\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "\n",
    "def get_intermediate_layer_output(layer_name, x_test):\n",
    "    layer = model.get_layer(name = layer_name)\n",
    "    intermediate_layer_model = keras.Model(inputs = model.input, outputs = layer.output)\n",
    "    return intermediate_layer_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from skimage import io\n",
    "\n",
    "def plot_convolutions_of_random_test_image():\n",
    "    viz_db = copy.deepcopy(dataset[\"test\"])\n",
    "    num = np.random.randint(len(viz_db[\"y\"]))\n",
    "    viz_db[\"X\"] = [viz_db[\"X\"][num]]\n",
    "    viz_db[\"y\"] = [viz_db[\"y\"][num]]\n",
    "    \n",
    "    plt.imshow(io.imread(viz_db[\"X\"][0]))\n",
    "    plt.show()\n",
    "    x_test, y_test = next(iter(covert_to_tf_dataset(viz_db, repeat = False)))\n",
    "    \n",
    "    print(\"conv1 visualization\")\n",
    "    visualize_conv_layer_out(get_intermediate_layer_output(\"conv1\", x_test))\n",
    "    \n",
    "    print(\"conv2 visualization\")\n",
    "    visualize_conv_layer_out(get_intermediate_layer_output(\"conv2\", x_test))\n",
    "    \n",
    "    print(\"-\" * 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Convolutions of 'n' random test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _ in np.arange(5):\n",
    "    plot_convolutions_of_random_test_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
